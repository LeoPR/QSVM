"""
Teste minimal para debug do travamento
"""
import pytest
import torch
import time
import tempfile
from pathlib import Path


# Teste 1: Fixture bÃ¡sica
def test_basic_torch():
    """Testa se torch funciona bÃ¡sico"""
    print("ğŸ” Testing basic torch...")
    x = torch.rand(3, 3)
    assert x.shape == (3, 3)
    print("âœ… Torch OK")


# Teste 2: Fixture synthetic
def test_tiny_synthetic_simple():
    """Testa fixture tiny_synthetic isoladamente"""
    print("ğŸ” Testing tiny_synthetic...")

    class TinySynthetic(torch.utils.data.Dataset):
        def __init__(self, n=2, size=(8, 8)):  # MUITO pequeno para debug
            print(f"  ğŸ”¨ Creating TinySynthetic n={n}, size={size}")
            self.n = n
            self.size = size

        def __len__(self):
            print(f"  ğŸ“ __len__ called, returning {self.n}")
            return self.n

        def __getitem__(self, idx):
            print(f"  ğŸ¯ __getitem__ called with idx={idx}")
            if idx >= self.n:
                raise IndexError(f"Index {idx} >= {self.n}")

            H, W = self.size
            # Gradiente SUPER simples
            img = torch.linspace(0, 1, H * W).view(1, H, W)
            label = idx
            print(f"  âœ… Generated img {img.shape}, label {label}")
            return img, label

    ds = TinySynthetic(n=2, size=(4, 4))
    print(f"âœ… Dataset created, len={len(ds)}")

    # Testar getitem
    img, label = ds[0]
    print(f"âœ… Got item 0: {img.shape}, {label}")
    print("âœ… TinySynthetic OK")


# Teste 3: ProcessedDataset bÃ¡sico
def test_processed_dataset_minimal():
    """Testa ProcessedDataset com config mÃ­nima"""
    print("ğŸ” Testing ProcessedDataset minimal...")

    # Dataset tiny
    class TinyDs(torch.utils.data.Dataset):
        def __len__(self): return 1

        def __getitem__(self, idx):
            return torch.full((1, 4, 4), 0.5), 0

    ds = TinyDs()
    print("âœ… Tiny dataset created")

    # Cache temporÃ¡rio
    with tempfile.TemporaryDirectory() as tmp_dir:
        print(f"  ğŸ“ Using temp cache: {tmp_dir}")

        try:
            # Import aqui para ver se trava
            print("  ğŸ“¦ Importing ProcessedDataset...")
            from patchkit import ProcessedDataset
            print("  âœ… Import OK")

            print("  ğŸ”¨ Creating ProcessedDataset...")
            start_time = time.time()

            processed = ProcessedDataset(
                ds,
                target_size=(4, 4),  # Mesmo tamanho - sem resize
                resize_alg=None,
                image_format=None,  # Sem compressÃ£o
                quality=None,
                quantization_levels=None,  # Sem quantizaÃ§Ã£o
                quantization_method='uniform',
                cache_dir=tmp_dir,
                cache_rebuild=True
            )

            elapsed = time.time() - start_time
            print(f"  â±ï¸ ProcessedDataset created in {elapsed:.2f}s")

            print(f"  ğŸ“Š Dataset length: {len(processed)}")
            print(f"  ğŸ“Š Data shape: {processed.data.shape}")
            print("âœ… ProcessedDataset minimal OK")

        except Exception as e:
            print(f"âŒ ProcessedDataset failed: {e}")
            import traceback
            traceback.print_exc()
            raise


# Teste 4: Com quantizaÃ§Ã£o
def test_processed_dataset_with_quantization():
    """Testa com quantizaÃ§Ã£o (possÃ­vel culpado)"""
    print("ğŸ” Testing ProcessedDataset with quantization...")

    class TinyDs(torch.utils.data.Dataset):
        def __len__(self): return 1

        def __getitem__(self, idx):
            return torch.rand(1, 8, 8), 0  # Random para quantizar

    ds = TinyDs()

    with tempfile.TemporaryDirectory() as tmp_dir:
        try:
            from patchkit import ProcessedDataset

            print("  ğŸ”¨ Creating with quantization...")
            start_time = time.time()

            processed = ProcessedDataset(
                ds,
                target_size=(8, 8),
                quantization_levels=2,  # Esta Ã© a possÃ­vel culpada
                quantization_method='uniform',
                cache_dir=tmp_dir,
                cache_rebuild=True
            )

            elapsed = time.time() - start_time
            print(f"  â±ï¸ With quantization: {elapsed:.2f}s")
            print("âœ… Quantization OK")

        except Exception as e:
            print(f"âŒ Quantization failed: {e}")
            raise


if __name__ == "__main__":
    print("ğŸš€ Running debug tests manually...")
    test_basic_torch()
    test_tiny_synthetic_simple()
    test_processed_dataset_minimal()
    test_processed_dataset_with_quantization()
    print("ğŸ‰ All debug tests passed!")